{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMbVCK8ydrFzEi0deZ+sZi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52454/Generative-AI_2025/blob/main/GenerativeAI_Lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Write Python code without using any libraries to find the value of x at which the\n",
        "function f(x) shown in equation (1) has minimum value. Consider Gradient Descent Algorithm.\n",
        "f (x) = 5x4 + 3x2 + 10"
      ],
      "metadata": {
        "id": "e-Ud5lrzudii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBo7Y0npsJUa",
        "outputId": "ca09ede1-e893-44d5-8092-c367a08bf5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of x for f(x) is 0.0\n"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "    return 5 * x**4 + 3 * x**2 + 10\n",
        "\n",
        "def f_prime(x):\n",
        "    return 20 * x**3 + 6 * x\n",
        "\n",
        "def gradient_descent(learning_rate, iterations):\n",
        "    x = 0  # Starting point\n",
        "    for _ in range(iterations):\n",
        "        x = x - learning_rate * f_prime(x)\n",
        "    return x\n",
        "\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "min_x = gradient_descent(learning_rate, iterations)\n",
        "print(f\"Minimum value of x for f(x) is {min_x}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Write Python code without using any libraries to find the value of x and y at which the\n",
        "function g(x,y) shown in equation (2) has minimum value. Consider Gradient Descent Algorithm.\n",
        "f (x) = 3x2 + 5e−y + 10"
      ],
      "metadata": {
        "id": "n0rFXuySurPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def g(x, y):\n",
        "    return 3 * x**2 + 5 * math.exp(-y) + 10\n",
        "\n",
        "def g_prime_x(x, y):\n",
        "    return 6 * x\n",
        "\n",
        "def g_prime_y(x, y):\n",
        "    return -5 * math.exp(-y)\n",
        "\n",
        "def gradient_descent_2d(learning_rate, iterations):\n",
        "    x, y = 0, 0  # Starting points\n",
        "    for _ in range(iterations):\n",
        "        x = x - learning_rate * g_prime_x(x, y)\n",
        "        y = y - learning_rate * g_prime_y(x, y)\n",
        "    return x, y\n",
        "\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "min_x, min_y = gradient_descent_2d(learning_rate, iterations)\n",
        "print(f\"Minimum values of x and y for g(x, y) are {min_x} and {min_y}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZefBPpFxsQYH",
        "outputId": "9a33451b-ed21-44db-ad07-fff5cd446529"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum values of x and y for g(x, y) are 0.0 and 3.9337602416246904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Write Python code without using any libraries to find the value of x at which the\n",
        "sigmoid function z(x) shown in equation (3) has minimum value. Consider Gradient Descent\n",
        "Algorithm.\n",
        "z(x) = 1\n",
        "1 + e−x"
      ],
      "metadata": {
        "id": "I6jV9pQWu6IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def z(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def z_prime(x):\n",
        "    sigmoid = z(x)\n",
        "    return sigmoid * (1 - sigmoid)\n",
        "\n",
        "def gradient_descent_sigmoid(learning_rate, iterations):\n",
        "    x = 0  # Starting point\n",
        "    for _ in range(iterations):\n",
        "        x = x - learning_rate * z_prime(x)\n",
        "    return x\n",
        "\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "min_x_sigmoid = gradient_descent_sigmoid(learning_rate, iterations)\n",
        "print(f\"Minimum value of x for z(x) is {min_x_sigmoid}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJNdJ-C6s6Mg",
        "outputId": "bc815a91-3de3-404b-9fd6-2d20294345ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of x for z(x) is -1.8618354629020137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Write Python code without using any libraries to find the value of optimal values of\n",
        "model parameters M and C such that the model’s Square Error Value shown in equation 4 will\n",
        "be minimum. It means model gives output close to expected output as shown in Figure 1"
      ],
      "metadata": {
        "id": "TiRyUf8ovD5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming we have the following data points\n",
        "expected_output = [1, 2, 3, 4, 5]\n",
        "predicted_output = [2, 3, 4, 5, 6]\n",
        "\n",
        "# Initialize the parameters\n",
        "M = 0\n",
        "C = 0\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Number of iterations\n",
        "iterations = 1000\n",
        "\n",
        "def predict(x, M, C):\n",
        "    return M * x + C\n",
        "\n",
        "def square_error(expected, predicted):\n",
        "    return (expected - predicted) ** 2\n",
        "\n",
        "def gradient_descent(expected_output, predicted_output, learning_rate, iterations):\n",
        "    global M, C\n",
        "    n = len(expected_output)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        dM = 0\n",
        "        dC = 0\n",
        "        for i in range(n):\n",
        "            dM += -2 * predicted_output[i] * (expected_output[i] - predict(predicted_output[i], M, C))\n",
        "            dC += -2 * (expected_output[i] - predict(predicted_output[i], M, C))\n",
        "        M -= (dM / n) * learning_rate\n",
        "        C -= (dC / n) * learning_rate\n",
        "\n",
        "    return M, C\n",
        "\n",
        "# Run gradient descent\n",
        "optimal_M, optimal_C = gradient_descent(expected_output, predicted_output, learning_rate, iterations)\n",
        "print(f\"Optimal values of M and C are: M = {optimal_M}, C = {optimal_C}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT41DFA7uVlF",
        "outputId": "2eab6eee-f4b1-4f5c-edb2-45f2997ec684"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal values of M and C are: M = 0.9687112245577285, C = -0.8600285123045526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xuc6rd2hucFE"
      }
    }
  ]
}